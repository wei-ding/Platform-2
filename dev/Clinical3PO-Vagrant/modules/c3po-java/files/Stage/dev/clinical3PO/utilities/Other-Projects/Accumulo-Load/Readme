
Pre-requisites :

1. Hadoop is installed properly and Hadoop Namenode and Datanode daemons are started.
2. Accumulo is installed properly and Accumulo servers are started.
3. Set the shell environment variables HADOOP_HOME pointing to Hadoop home directory.
4. Set the shell environment variables ACCUMULO_HOME pointing to Accumulo home directory.

Assumptions :

1. The accumulo instance name is c3po.
2. Zookeeper is running on localhost and listening on port 2181.
3. Accumulo root user password is c3po123.
4. The concept table data file name is concept.txt.
5. The death table data file name is death.txt.
6. The observation table data files are under directory Observation*/observation[1..100].txt.

In case of any mismatch, edit load_accumulo.sh and modify c3po with the accumulo instance name,
localhost:2181 with <zookeeper server host>:<port>, c3po123 with root user password.

Procedure :

1. Run compile.sh to compile the sources - LoadConcept.java, LoadDeath.java and
   LoadObservation.java.
2. Copy the class files generated after compilation to the directory where the files to be
   loaded are present.
3. Run load_accumulo.sh to load the data.

Accumulo Table Line Count:
    accumulo shell -u username -p password -e "scan -t tablename -np" | wc -l
    Note: Do use only on small tables. Dont on huge tons of tables.

